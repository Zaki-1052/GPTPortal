{
  "models": {
    "gpt-4": {
      "id": "gpt-4",
      "name": "GPT-4: Original",
      "provider": "openai",
      "category": "gpt",
      "source": "core",
      "description": "Original GPT-4 model",
      "pricing": { "input": 30.00, "output": 60.00 },
      "contextWindow": 8192,
      "maxTokens": 6000,
      "supportsVision": false,
      "supportsFunction": true
    },
    "gpt-4o": {
      "id": "gpt-4o",
      "name": "GPT-4o: Latest",
      "provider": "openai",
      "category": "gpt",
      "source": "core",
      "description": "Most capable GPT-4 model",
      "pricing": { "input": 2.50, "output": 10.00, "cached": 1.25 },
      "contextWindow": 128000,
      "maxTokens": 16000,
      "supportsVision": true,
      "supportsFunction": true
    },
    "gpt-4o-mini": {
      "id": "gpt-4o-mini",
      "name": "GPT-4o Mini: Cheapest",
      "provider": "openai",
      "category": "gpt",
      "source": "core",
      "description": "Affordable GPT-4 model",
      "pricing": { "input": 0.15, "output": 0.60, "cached": 0.075 },
      "contextWindow": 128000,
      "maxTokens": 16000,
      "supportsVision": true,
      "supportsFunction": true
    },
    "gpt-4-turbo": {
      "id": "gpt-4-turbo",
      "name": "GPT-4 Turbo: Standard",
      "provider": "openai",
      "category": "gpt",
      "source": "core",
      "description": "Fast GPT-4 model",
      "pricing": { "input": 10.00, "output": 30.00 },
      "contextWindow": 128000,
      "maxTokens": 16000,
      "supportsVision": true,
      "supportsFunction": true
    },
    "gpt-3.5-turbo-0125": {
      "id": "gpt-3.5-turbo-0125",
      "name": "GPT-3.5 Turbo: Legacy",
      "provider": "openai",
      "category": "gpt",
      "source": "core",
      "description": "Legacy GPT-3.5 model",
      "pricing": { "input": 0.50, "output": 1.50 },
      "contextWindow": 16385,
      "maxTokens": 8000,
      "supportsVision": false,
      "supportsFunction": true
    },

    "gpt-image-1": {
      "id": "gpt-image-1",
      "name": "GPT Image 1: Advanced",
      "provider": "openai",
      "category": "image",
      "source": "core",
      "description": "Advanced multimodal image generation model",
      "pricing": { "input": 2.50, "output": 10.00 },
      "contextWindow": 128000,
      "maxTokens": 16000,
      "supportsVision": true,
      "supportsFunction": true,
      "supportsImageGeneration": true,
      "imageTokens": {
        "low": { "1024x1024": 272, "1024x1536": 408, "1536x1024": 400 },
        "medium": { "1024x1024": 1056, "1024x1536": 1584, "1536x1024": 1568 },
        "high": { "1024x1024": 4160, "1024x1536": 6240, "1536x1024": 6208 }
      }
    },
    "dall-e-3": {
      "id": "dall-e-3",
      "name": "DALL-E 3: Specialized",
      "provider": "openai",
      "category": "image",
      "source": "core",
      "description": "Specialized image generation model",
      "pricing": { "input": 0, "output": 0.04 },
      "contextWindow": 4000,
      "maxTokens": 1000,
      "supportsVision": false,
      "supportsFunction": false,
      "supportsImageGeneration": true,
      "imageConfig": {
        "quality": ["standard", "hd"],
        "size": ["1024x1024", "1024x1792", "1792x1024"],
        "style": ["vivid", "natural"]
      }
    },
    "dall-e-2": {
      "id": "dall-e-2",
      "name": "DALL-E 2: Fast",
      "provider": "openai",
      "category": "image",
      "source": "core",
      "description": "Fast image generation model",
      "pricing": { "input": 0, "output": 0.02 },
      "contextWindow": 1000,
      "maxTokens": 1000,
      "supportsVision": false,
      "supportsFunction": false,
      "supportsImageGeneration": true,
      "imageConfig": {
        "quality": ["standard"],
        "size": ["256x256", "512x512", "1024x1024"],
        "style": ["vivid", "natural"]
      }
    },

    "o1-preview": {
      "id": "o1-preview",
      "name": "GPT-o1 Preview: Reasoning",
      "provider": "openai",
      "category": "reasoning",
      "source": "core",
      "description": "Advanced reasoning model",
      "pricing": { "input": 15.00, "output": 60.00, "cached": 7.50 },
      "contextWindow": 128000,
      "maxTokens": 8000,
      "supportsVision": false,
      "supportsFunction": false
    },
    "o1-mini": {
      "id": "o1-mini",
      "name": "GPT-o1 Mini: Cheap Reasoning",
      "provider": "openai",
      "category": "reasoning",
      "source": "core",
      "description": "Affordable reasoning model",
      "pricing": { "input": 1.10, "output": 4.40, "cached": 0.55 },
      "contextWindow": 128000,
      "maxTokens": 8000,
      "supportsVision": false,
      "supportsFunction": false
    },
    "o3-mini": {
      "id": "o3-mini",
      "name": "GPT-o3 Mini: Cheap Reasoning",
      "provider": "openai",
      "category": "reasoning",
      "source": "core",
      "description": "Latest affordable reasoning model",
      "pricing": { "input": 1.10, "output": 4.40, "cached": 0.55 },
      "contextWindow": 128000,
      "maxTokens": 8000,
      "supportsVision": false,
      "supportsFunction": false
    },

    "claude-opus-4-20250514": {
      "id": "claude-opus-4-20250514",
      "name": "Claude 4 Opus",
      "provider": "anthropic",
      "category": "claude",
      "source": "core",
      "description": "Most capable Claude model",
      "pricing": { "input": 15.00, "output": 75.00 },
      "contextWindow": 200000,
      "maxTokens": 100000,
      "supportsVision": true,
      "supportsFunction": true
    },
    "claude-sonnet-4-20250514": {
      "id": "claude-sonnet-4-20250514",
      "name": "Claude 4 Sonnet",
      "provider": "anthropic",
      "category": "claude",
      "source": "core",
      "description": "Balanced Claude model",
      "pricing": { "input": 3.00, "output": 15.00 },
      "contextWindow": 200000,
      "maxTokens": 100000,
      "supportsVision": true,
      "supportsFunction": true
    },
    "claude-3-7-sonnet-latest": {
      "id": "claude-3-7-sonnet-latest",
      "name": "Claude 3.7 Sonnet",
      "provider": "anthropic",
      "category": "claude",
      "source": "core",
      "description": "Enhanced Claude 3.5 model",
      "pricing": { "input": 3.00, "output": 15.00 },
      "contextWindow": 200000,
      "maxTokens": 100000,
      "supportsVision": true,
      "supportsFunction": true
    },
    "claude-3-5-sonnet-latest": {
      "id": "claude-3-5-sonnet-latest",
      "name": "Claude 3.5 Sonnet",
      "provider": "anthropic",
      "category": "claude",
      "source": "core",
      "description": "Advanced Claude model",
      "pricing": { "input": 3.00, "output": 15.00 },
      "contextWindow": 200000,
      "maxTokens": 8000,
      "supportsVision": true,
      "supportsFunction": true
    },
    "claude-3-5-haiku-latest": {
      "id": "claude-3-5-haiku-latest",
      "name": "Claude 3.5 Haiku",
      "provider": "anthropic",
      "category": "claude",
      "source": "core",
      "description": "Fast Claude model",
      "pricing": { "input": 0.25, "output": 1.25 },
      "contextWindow": 200000,
      "maxTokens": 8000,
      "supportsVision": true,
      "supportsFunction": true
    },
    "claude-3-haiku-20240307": {
      "id": "claude-3-haiku-20240307",
      "name": "Claude Haiku: Cheap",
      "provider": "anthropic",
      "category": "claude",
      "source": "core",
      "description": "Affordable Claude model",
      "pricing": { "input": 0.25, "output": 1.25 },
      "contextWindow": 200000,
      "maxTokens": 8000,
      "supportsVision": true,
      "supportsFunction": true
    },

    "gemini-2.0-flash-exp": {
      "id": "gemini-2.0-flash-exp",
      "name": "Gemini 2.0 Flash",
      "provider": "google",
      "category": "gemini",
      "source": "core",
      "description": "Latest Gemini model",
      "pricing": { "input": 0, "output": 0 },
      "contextWindow": 1000000,
      "maxTokens": 8000,
      "supportsVision": true,
      "supportsFunction": true
    },
    "gemini-1.5-pro": {
      "id": "gemini-1.5-pro",
      "name": "Gemini 1.5 Pro: Best",
      "provider": "google",
      "category": "gemini",
      "source": "core",
      "description": "Most capable Gemini model",
      "pricing": { "input": 0, "output": 0 },
      "contextWindow": 2000000,
      "maxTokens": 8000,
      "supportsVision": true,
      "supportsFunction": true
    },
    "gemini-1.5-flash": {
      "id": "gemini-1.5-flash",
      "name": "Gemini 1.5 Flash",
      "provider": "google",
      "category": "gemini",
      "source": "core",
      "description": "Fast Gemini model",
      "pricing": { "input": 0, "output": 0 },
      "contextWindow": 1000000,
      "maxTokens": 8000,
      "supportsVision": true,
      "supportsFunction": true
    },
    "gemini-pro": {
      "id": "gemini-pro",
      "name": "Gemini Pro",
      "provider": "google",
      "category": "gemini",
      "source": "core",
      "description": "Standard Gemini model",
      "pricing": { "input": 0, "output": 0 },
      "contextWindow": 30720,
      "maxTokens": 8000,
      "supportsVision": false,
      "supportsFunction": true
    },

    "deepseek-reasoner": {
      "id": "deepseek-reasoner",
      "name": "DeepSeek-R1",
      "provider": "deepseek",
      "category": "deepseek",
      "source": "core",
      "description": "DeepSeek reasoning model",
      "pricing": { "input": 0.55, "output": 2.19 },
      "contextWindow": 64000,
      "maxTokens": 8000,
      "supportsVision": false,
      "supportsFunction": true
    },
    "deepseek-chat": {
      "id": "deepseek-chat",
      "name": "DeepSeek-Chat",
      "provider": "deepseek",
      "category": "deepseek",
      "source": "core",
      "description": "DeepSeek conversational model",
      "pricing": { "input": 0.14, "output": 0.28 },
      "contextWindow": 64000,
      "maxTokens": 8000,
      "supportsVision": false,
      "supportsFunction": true
    },

    "llama-3.1-405b-reasoning": {
      "id": "llama-3.1-405b-reasoning",
      "name": "Llama 3.1 405B",
      "provider": "groq",
      "category": "llama",
      "source": "core",
      "description": "Largest LLaMA model",
      "pricing": { "input": 0, "output": 0 },
      "contextWindow": 131072,
      "maxTokens": 8000,
      "supportsVision": false,
      "supportsFunction": true
    },
    "llama-3.1-70b-versatile": {
      "id": "llama-3.1-70b-versatile",
      "name": "Llama 3.1 70B",
      "provider": "groq",
      "category": "llama",
      "source": "core",
      "description": "Versatile LLaMA model",
      "pricing": { "input": 0, "output": 0 },
      "contextWindow": 131072,
      "maxTokens": 8000,
      "supportsVision": false,
      "supportsFunction": true
    },
    "llama-3.1-8b-instant": {
      "id": "llama-3.1-8b-instant",
      "name": "Llama 3.1 8B",
      "provider": "groq",
      "category": "llama",
      "source": "core",
      "description": "Fast LLaMA model",
      "pricing": { "input": 0, "output": 0 },
      "contextWindow": 131072,
      "maxTokens": 8000,
      "supportsVision": false,
      "supportsFunction": true
    },

    "mistral-large-latest": {
      "id": "mistral-large-latest",
      "name": "Mistral Large",
      "provider": "mistral",
      "category": "mistral",
      "source": "core",
      "description": "Largest Mistral model",
      "pricing": { "input": 2.00, "output": 6.00 },
      "contextWindow": 128000,
      "maxTokens": 8000,
      "supportsVision": false,
      "supportsFunction": true
    },
    "codestral-latest": {
      "id": "codestral-latest",
      "name": "Codestral",
      "provider": "mistral",
      "category": "mistral",
      "source": "core",
      "description": "Mistral coding model",
      "pricing": { "input": 1.00, "output": 3.00 },
      "contextWindow": 32000,
      "maxTokens": 8000,
      "supportsVision": false,
      "supportsFunction": true
    },

    "gpt-4o-mini-tts": {
      "id": "gpt-4o-mini-tts",
      "name": "GPT-4o Mini TTS: Advanced",
      "provider": "openai",
      "category": "voice",
      "source": "core",
      "description": "Most reliable text-to-speech model with intelligent controls",
      "pricing": { "input": 0.15, "output": 0.60 },
      "contextWindow": 128000,
      "maxTokens": 16000,
      "supportsVision": false,
      "supportsFunction": false,
      "supportsTextToSpeech": true,
      "voiceOptions": ["alloy", "ash", "ballad", "coral", "echo", "fable", "nova", "onyx", "sage", "shimmer"],
      "audioFormats": ["mp3", "opus", "aac", "flac", "wav", "pcm"],
      "features": ["streaming", "instructions", "emotion_control", "speed_control", "accent_control"]
    },
    "tts-1-hd": {
      "id": "tts-1-hd",
      "name": "TTS-1 HD: High Quality",
      "provider": "openai",
      "category": "voice",
      "source": "core",
      "description": "High-definition text-to-speech model",
      "pricing": { "input": 0, "output": 0.015 },
      "contextWindow": 4000,
      "maxTokens": 1000,
      "supportsVision": false,
      "supportsFunction": false,
      "supportsTextToSpeech": true,
      "voiceOptions": ["alloy", "echo", "fable", "onyx", "nova", "shimmer"],
      "audioFormats": ["mp3", "opus", "aac", "flac"]
    },
    "tts-1": {
      "id": "tts-1",
      "name": "TTS-1: Standard",
      "provider": "openai",
      "category": "voice",
      "source": "core",
      "description": "Standard text-to-speech model with lower latency",
      "pricing": { "input": 0, "output": 0.015 },
      "contextWindow": 4000,
      "maxTokens": 1000,
      "supportsVision": false,
      "supportsFunction": false,
      "supportsTextToSpeech": true,
      "voiceOptions": ["alloy", "echo", "fable", "onyx", "nova", "shimmer"],
      "audioFormats": ["mp3", "opus", "aac", "flac"]
    },

    "gpt-4o-transcribe": {
      "id": "gpt-4o-transcribe",
      "name": "GPT-4o Transcribe: Best",
      "provider": "openai",
      "category": "voice",
      "source": "core",
      "description": "Highest quality speech-to-text model with intelligent prompting",
      "pricing": { "input": 2.50, "output": 10.00 },
      "contextWindow": 128000,
      "maxTokens": 16000,
      "supportsVision": false,
      "supportsFunction": false,
      "supportsSpeechToText": true,
      "audioFormats": ["mp3", "mp4", "mpeg", "mpga", "m4a", "wav", "webm"],
      "features": ["streaming", "prompting", "json_output", "text_output"],
      "maxFileSize": "25MB"
    },
    "gpt-4o-mini-transcribe": {
      "id": "gpt-4o-mini-transcribe",
      "name": "GPT-4o Mini Transcribe: Fast",
      "provider": "openai",
      "category": "voice",
      "source": "core",
      "description": "Fast and affordable speech-to-text model",
      "pricing": { "input": 0.15, "output": 0.60 },
      "contextWindow": 128000,
      "maxTokens": 16000,
      "supportsVision": false,
      "supportsFunction": false,
      "supportsSpeechToText": true,
      "audioFormats": ["mp3", "mp4", "mpeg", "mpga", "m4a", "wav", "webm"],
      "features": ["streaming", "prompting", "json_output", "text_output"],
      "maxFileSize": "25MB"
    },
    "whisper-1": {
      "id": "whisper-1",
      "name": "Whisper-1: Legacy",
      "provider": "openai",
      "category": "voice",
      "source": "core",
      "description": "Original Whisper speech-to-text model",
      "pricing": { "input": 0, "output": 0.006 },
      "contextWindow": 25000,
      "maxTokens": 1000,
      "supportsVision": false,
      "supportsFunction": false,
      "supportsSpeechToText": true,
      "audioFormats": ["mp3", "mp4", "mpeg", "mpga", "m4a", "wav", "webm"],
      "features": ["timestamps", "translations", "verbose_json", "srt", "vtt"],
      "maxFileSize": "25MB"
    }
  },
  
  "categories": {
    "gpt": {
      "name": "GPT Models",
      "models": ["gpt-4o", "gpt-4o-mini", "gpt-4-turbo", "gpt-4", "gpt-3.5-turbo-0125"]
    },
    "image": {
      "name": "Image Generation",
      "models": ["gpt-image-1", "dall-e-3", "dall-e-2"]
    },
    "claude": {
      "name": "Claude Models",
      "models": ["claude-opus-4-20250514", "claude-sonnet-4-20250514", "claude-3-7-sonnet-latest", "claude-3-5-sonnet-latest", "claude-3-5-haiku-latest", "claude-3-haiku-20240307"]
    },
    "reasoning": {
      "name": "Reasoning Models",
      "models": ["o1-preview", "o1-mini", "o3-mini", "deepseek-reasoner"]
    },
    "gemini": {
      "name": "Gemini Models",
      "models": ["gemini-2.0-flash-exp", "gemini-1.5-pro", "gemini-1.5-flash", "gemini-pro"]
    },
    "llama": {
      "name": "LLaMA Models",
      "models": ["llama-3.1-405b-reasoning", "llama-3.1-70b-versatile", "llama-3.1-8b-instant"]
    },
    "mistral": {
      "name": "Mistral Models",
      "models": ["mistral-large-latest", "codestral-latest"]
    },
    "deepseek": {
      "name": "DeepSeek Models",
      "models": ["deepseek-reasoner", "deepseek-chat"]
    },
    "voice": {
      "name": "Voice Models",
      "models": ["gpt-4o-mini-tts", "tts-1-hd", "tts-1", "gpt-4o-transcribe", "gpt-4o-mini-transcribe", "whisper-1"]
    }
  }
}