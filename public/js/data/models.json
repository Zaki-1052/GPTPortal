{
  "models": {
    "gpt-4": {
      "id": "gpt-4",
      "name": "GPT-4: Original",
      "provider": "openai",
      "category": "gpt",
      "source": "core",
      "description": "Original GPT-4 model",
      "pricing": { "input": 30.00, "output": 60.00 },
      "contextWindow": 8192,
      "maxTokens": 6000,
      "supportsVision": false,
      "supportsFunction": true
    },
    "gpt-4o": {
      "id": "gpt-4o",
      "name": "GPT-4o: Latest",
      "provider": "openai",
      "category": "gpt",
      "source": "core",
      "description": "Most capable GPT-4 model",
      "pricing": { "input": 2.50, "output": 10.00, "cached": 1.25 },
      "contextWindow": 128000,
      "maxTokens": 16000,
      "supportsVision": true,
      "supportsFunction": true
    },
    "gpt-4o-mini": {
      "id": "gpt-4o-mini",
      "name": "GPT-4o Mini: Cheapest",
      "provider": "openai",
      "category": "gpt",
      "source": "core",
      "description": "Affordable GPT-4 model",
      "pricing": { "input": 0.15, "output": 0.60, "cached": 0.075 },
      "contextWindow": 128000,
      "maxTokens": 16000,
      "supportsVision": true,
      "supportsFunction": true
    },
    "gpt-4-turbo": {
      "id": "gpt-4-turbo",
      "name": "GPT-4 Turbo: Standard",
      "provider": "openai",
      "category": "gpt",
      "source": "core",
      "description": "Fast GPT-4 model",
      "pricing": { "input": 10.00, "output": 30.00 },
      "contextWindow": 128000,
      "maxTokens": 16000,
      "supportsVision": true,
      "supportsFunction": true
    },
    "gpt-3.5-turbo-0125": {
      "id": "gpt-3.5-turbo-0125",
      "name": "GPT-3.5 Turbo: Legacy",
      "provider": "openai",
      "category": "gpt",
      "source": "core",
      "description": "Legacy GPT-3.5 model",
      "pricing": { "input": 0.50, "output": 1.50 },
      "contextWindow": 16385,
      "maxTokens": 8000,
      "supportsVision": false,
      "supportsFunction": true
    },

    "gpt-4.1": {
      "id": "gpt-4.1",
      "name": "GPT-4.1: Latest",
      "provider": "openai",
      "category": "gpt",
      "source": "core",
      "description": "Latest GPT-4.1 model with enhanced capabilities",
      "pricing": { "input": 2.00, "output": 8.00, "cached": 0.50 },
      "contextWindow": 128000,
      "maxTokens": 16000,
      "supportsVision": true,
      "supportsFunction": true
    },
    "gpt-4.1-mini": {
      "id": "gpt-4.1-mini",
      "name": "GPT-4.1 Mini: Fast",
      "provider": "openai",
      "category": "gpt",
      "source": "core",
      "description": "Fast and efficient GPT-4.1 model",
      "pricing": { "input": 0.40, "output": 1.60, "cached": 0.10 },
      "contextWindow": 128000,
      "maxTokens": 16000,
      "supportsVision": true,
      "supportsFunction": true
    },
    "gpt-4.1-nano": {
      "id": "gpt-4.1-nano",
      "name": "GPT-4.1 Nano: Cheapest",
      "provider": "openai",
      "category": "gpt",
      "source": "core",
      "description": "Most affordable GPT-4.1 model",
      "pricing": { "input": 0.10, "output": 0.40, "cached": 0.025 },
      "contextWindow": 128000,
      "maxTokens": 16000,
      "supportsVision": true,
      "supportsFunction": true
    },

    "gpt-5": {
      "id": "gpt-5",
      "name": "GPT-5: Most Intelligent",
      "provider": "openai",
      "category": "gpt",
      "source": "core",
      "description": "Most intelligent GPT model with advanced reasoning, code generation, and long context capabilities",
      "pricing": { "input": 1.25, "output": 10.00, "cached": 0.125 },
      "contextWindow": 400000,
      "maxTokens": 128000,
      "supportsVision": true,
      "supportsFunction": true,
      "supportsReasoning": true
    },
    "gpt-5-mini": {
      "id": "gpt-5-mini",
      "name": "GPT-5 Mini: Balanced",
      "provider": "openai",
      "category": "gpt",
      "source": "core",
      "description": "Cost-optimized reasoning and chat model that balances speed, cost, and capability",
      "pricing": { "input": 0.25, "output": 2.00, "cached": 0.025 },
      "contextWindow": 400000,
      "maxTokens": 128000,
      "supportsVision": true,
      "supportsFunction": true,
      "supportsReasoning": true
    },
    "gpt-5-nano": {
      "id": "gpt-5-nano",
      "name": "GPT-5 Nano: Efficient",
      "provider": "openai",
      "category": "gpt",
      "source": "core",
      "description": "High-throughput model for simple instruction-following and classification tasks",
      "pricing": { "input": 0.05, "output": 0.40, "cached": 0.005 },
      "contextWindow": 400000,
      "maxTokens": 128000,
      "supportsVision": true,
      "supportsFunction": true,
      "supportsReasoning": true
    },
    "gpt-5-chat-latest": {
      "id": "gpt-5-chat-latest",
      "name": "GPT-5 Chat: Latest",
      "provider": "openai",
      "category": "gpt",
      "source": "core",
      "description": "Latest GPT-5 model optimized for conversational interactions",
      "pricing": { "input": 1.25, "output": 10.00, "cached": 0.125 },
      "contextWindow": 400000,
      "maxTokens": 128000,
      "supportsVision": true,
      "supportsFunction": true,
      "supportsReasoning": true
    },


    "o1-preview": {
      "id": "o1-preview",
      "name": "GPT-o1 Preview: Reasoning",
      "provider": "openai",
      "category": "reasoning",
      "source": "core",
      "description": "Advanced reasoning model",
      "pricing": { "input": 15.00, "output": 60.00, "cached": 7.50 },
      "contextWindow": 128000,
      "maxTokens": 8000,
      "supportsVision": false,
      "supportsFunction": false
    },
    "o1-mini": {
      "id": "o1-mini",
      "name": "GPT-o1 Mini: Cheap Reasoning",
      "provider": "openai",
      "category": "reasoning",
      "source": "core",
      "description": "Affordable reasoning model",
      "pricing": { "input": 1.10, "output": 4.40, "cached": 0.55 },
      "contextWindow": 128000,
      "maxTokens": 8000,
      "supportsVision": false,
      "supportsFunction": false
    },
    "o3-mini": {
      "id": "o3-mini",
      "name": "GPT-o3 Mini: Cheap Reasoning",
      "provider": "openai",
      "category": "reasoning",
      "source": "core",
      "description": "Latest affordable reasoning model",
      "pricing": { "input": 1.10, "output": 4.40, "cached": 0.55 },
      "contextWindow": 128000,
      "maxTokens": 8000,
      "supportsVision": false,
      "supportsFunction": false
    },
    "o3": {
      "id": "o3",
      "name": "GPT-o3: Advanced Reasoning",
      "provider": "openai",
      "category": "reasoning",
      "source": "core",
      "description": "Most advanced O3 reasoning model",
      "pricing": { "input": 10.00, "output": 40.00, "cached": 2.50 },
      "contextWindow": 128000,
      "maxTokens": 8000,
      "supportsVision": false,
      "supportsFunction": false
    },
    "o3-pro": {
      "id": "o3-pro",
      "name": "GPT-o3 Pro: Maximum Reasoning",
      "provider": "openai",
      "category": "reasoning",
      "source": "core",
      "description": "Version of o3 with more compute for better responses",
      "pricing": { "input": 20.00, "output": 80.00 },
      "contextWindow": 200000,
      "maxTokens": 100000,
      "supportsVision": true,
      "supportsFunction": false
    },
    "o1-pro": {
      "id": "o1-pro",
      "name": "GPT-o1 Pro: Advanced Reasoning",
      "provider": "openai",
      "category": "reasoning",
      "source": "core",
      "description": "Version of o1 with more compute for better responses",
      "pricing": { "input": 150.00, "output": 600.00 },
      "contextWindow": 200000,
      "maxTokens": 100000,
      "supportsVision": true,
      "supportsFunction": false
    },
    "o4-mini": {
      "id": "o4-mini",
      "name": "GPT-o4 Mini: Next-Gen Reasoning",
      "provider": "openai",
      "category": "reasoning",
      "source": "core",
      "description": "Next generation affordable reasoning model",
      "pricing": { "input": 1.10, "output": 4.40, "cached": 0.275 },
      "contextWindow": 128000,
      "maxTokens": 8000,
      "supportsVision": false,
      "supportsFunction": false
    },

    "claude-opus-4-20250514": {
      "id": "claude-opus-4-20250514",
      "name": "Claude 4 Opus",
      "provider": "anthropic",
      "category": "claude",
      "source": "core",
      "description": "Most capable Claude model",
      "pricing": { "input": 15.00, "output": 75.00, "cached": 1.50, "cacheWrite": 18.75 },
      "contextWindow": 200000,
      "maxTokens": 32000,
      "supportsVision": true,
      "supportsFunction": true
    },
    "claude-sonnet-4-20250514": {
      "id": "claude-sonnet-4-20250514",
      "name": "Claude 4 Sonnet",
      "provider": "anthropic",
      "category": "claude",
      "source": "core",
      "description": "Balanced Claude model",
      "pricing": { "input": 3.00, "output": 15.00, "cached": 0.30, "cacheWrite": 3.75 },
      "contextWindow": 200000,
      "maxTokens": 64000,
      "supportsVision": true,
      "supportsFunction": true
    },
    "claude-3-7-sonnet-latest": {
      "id": "claude-3-7-sonnet-latest",
      "name": "Claude 3.7 Sonnet",
      "provider": "anthropic",
      "category": "claude",
      "source": "core",
      "description": "Enhanced Claude 3.5 model",
      "pricing": { "input": 3.00, "output": 15.00, "cached": 0.30, "cacheWrite": 3.75 },
      "contextWindow": 200000,
      "maxTokens": 100000,
      "supportsVision": true,
      "supportsFunction": true
    },
    "claude-3-5-sonnet-latest": {
      "id": "claude-3-5-sonnet-latest",
      "name": "Claude 3.5 Sonnet",
      "provider": "anthropic",
      "category": "claude",
      "source": "core",
      "description": "Advanced Claude model",
      "pricing": { "input": 3.00, "output": 15.00, "cached": 0.30, "cacheWrite": 3.75 },
      "contextWindow": 200000,
      "maxTokens": 8000,
      "supportsVision": true,
      "supportsFunction": true
    },
    "claude-3-5-haiku-latest": {
      "id": "claude-3-5-haiku-latest",
      "name": "Claude 3.5 Haiku",
      "provider": "anthropic",
      "category": "claude",
      "source": "core",
      "description": "Fast Claude model",
      "pricing": { "input": 0.25, "output": 1.25, "cached": 0.025, "cacheWrite": 0.3125 },
      "contextWindow": 200000,
      "maxTokens": 8000,
      "supportsVision": true,
      "supportsFunction": true
    },
    "claude-3-haiku-20240307": {
      "id": "claude-3-haiku-20240307",
      "name": "Claude Haiku: Cheap",
      "provider": "anthropic",
      "category": "claude",
      "source": "core",
      "description": "Affordable Claude model",
      "pricing": { "input": 0.25, "output": 1.25, "cached": 0.025, "cacheWrite": 0.3125 },
      "contextWindow": 200000,
      "maxTokens": 8000,
      "supportsVision": true,
      "supportsFunction": true
    },

    "gemini-2.0-flash-exp": {
      "id": "gemini-2.0-flash-exp",
      "name": "Gemini 2.0 Flash",
      "provider": "google",
      "category": "gemini",
      "source": "core",
      "description": "Latest Gemini model",
      "pricing": { "input": 0, "output": 0 },
      "contextWindow": 1000000,
      "maxTokens": 8000,
      "supportsVision": true,
      "supportsFunction": true
    },
    "gemini-1.5-pro": {
      "id": "gemini-1.5-pro",
      "name": "Gemini 1.5 Pro: Best",
      "provider": "google",
      "category": "gemini",
      "source": "core",
      "description": "Most capable Gemini model",
      "pricing": { "input": 0, "output": 0 },
      "contextWindow": 2000000,
      "maxTokens": 8000,
      "supportsVision": true,
      "supportsFunction": true
    },
    "gemini-1.5-flash": {
      "id": "gemini-1.5-flash",
      "name": "Gemini 1.5 Flash",
      "provider": "google",
      "category": "gemini",
      "source": "core",
      "description": "Fast Gemini model",
      "pricing": { "input": 0, "output": 0 },
      "contextWindow": 1000000,
      "maxTokens": 8000,
      "supportsVision": true,
      "supportsFunction": true
    },
    "gemini-pro": {
      "id": "gemini-pro",
      "name": "Gemini Pro",
      "provider": "google",
      "category": "gemini",
      "source": "core",
      "description": "Standard Gemini model",
      "pricing": { "input": 0, "output": 0 },
      "contextWindow": 30720,
      "maxTokens": 8000,
      "supportsVision": false,
      "supportsFunction": true
    },

    "gemini-2.5-flash-preview-05-20": {
      "id": "gemini-2.5-flash-preview-05-20",
      "name": "Gemini 2.5 Flash Preview",
      "provider": "google",
      "category": "gemini",
      "source": "core",
      "description": "Latest Gemini 2.5 with adaptive thinking and cost efficiency",
      "pricing": { "input": 0, "output": 0 },
      "contextWindow": 1000000,
      "maxTokens": 8000,
      "supportsVision": true,
      "supportsFunction": true
    },
    "gemini-2.5-pro-preview-05-06": {
      "id": "gemini-2.5-pro-preview-05-06",
      "name": "Gemini 2.5 Pro Preview",
      "provider": "google",
      "category": "gemini",
      "source": "core",
      "description": "Enhanced thinking and reasoning, multimodal understanding, advanced coding",
      "pricing": { "input": 0, "output": 0 },
      "contextWindow": 2000000,
      "maxTokens": 8000,
      "supportsVision": true,
      "supportsFunction": true
    },
    "gemini-2.0-flash-lite": {
      "id": "gemini-2.0-flash-lite",
      "name": "Gemini 2.0 Flash Lite",
      "provider": "google",
      "category": "gemini",
      "source": "core",
      "description": "Cost efficient and low latency version of Gemini 2.0",
      "pricing": { "input": 0, "output": 0 },
      "contextWindow": 1000000,
      "maxTokens": 8000,
      "supportsVision": true,
      "supportsFunction": true
    },
    "gemini-1.5-flash-8b": {
      "id": "gemini-1.5-flash-8b",
      "name": "Gemini 1.5 Flash 8B",
      "provider": "google",
      "category": "gemini",
      "source": "core",
      "description": "High volume and lower intelligence tasks",
      "pricing": { "input": 0, "output": 0 },
      "contextWindow": 1000000,
      "maxTokens": 8000,
      "supportsVision": true,
      "supportsFunction": true
    },

    "deepseek-reasoner": {
      "id": "deepseek-reasoner",
      "name": "DeepSeek-R1",
      "provider": "deepseek",
      "category": "deepseek",
      "source": "core",
      "description": "DeepSeek reasoning model",
      "pricing": { "input": 0.55, "output": 2.19 },
      "contextWindow": 64000,
      "maxTokens": 8000,
      "supportsVision": false,
      "supportsFunction": true
    },
    "deepseek-chat": {
      "id": "deepseek-chat",
      "name": "DeepSeek-Chat",
      "provider": "deepseek",
      "category": "deepseek",
      "source": "core",
      "description": "DeepSeek conversational model",
      "pricing": { "input": 0.14, "output": 0.28 },
      "contextWindow": 64000,
      "maxTokens": 8000,
      "supportsVision": false,
      "supportsFunction": true
    },

    "llama-3.1-405b-reasoning": {
      "id": "llama-3.1-405b-reasoning",
      "name": "Llama 3.1 405B",
      "provider": "groq",
      "category": "llama",
      "source": "core",
      "description": "Largest LLaMA model",
      "pricing": { "input": 0, "output": 0 },
      "contextWindow": 131072,
      "maxTokens": 8000,
      "supportsVision": false,
      "supportsFunction": true
    },
    "llama-3.1-70b-versatile": {
      "id": "llama-3.1-70b-versatile",
      "name": "Llama 3.1 70B",
      "provider": "groq",
      "category": "llama",
      "source": "core",
      "description": "Versatile LLaMA model",
      "pricing": { "input": 0, "output": 0 },
      "contextWindow": 131072,
      "maxTokens": 8000,
      "supportsVision": false,
      "supportsFunction": true
    },
    "llama-3.1-8b-instant": {
      "id": "llama-3.1-8b-instant",
      "name": "Llama 3.1 8B",
      "provider": "groq",
      "category": "llama",
      "source": "core",
      "description": "Fast LLaMA model",
      "pricing": { "input": 0, "output": 0 },
      "contextWindow": 131072,
      "maxTokens": 8000,
      "supportsVision": false,
      "supportsFunction": true
    },

    "mistral-large-latest": {
      "id": "mistral-large-latest",
      "name": "Mistral Large",
      "provider": "mistral",
      "category": "mistral",
      "source": "core",
      "description": "Largest Mistral model",
      "pricing": { "input": 2.00, "output": 6.00 },
      "contextWindow": 128000,
      "maxTokens": 8000,
      "supportsVision": false,
      "supportsFunction": true
    },
    "codestral-latest": {
      "id": "codestral-latest",
      "name": "Codestral",
      "provider": "mistral",
      "category": "mistral",
      "source": "core",
      "description": "Mistral coding model",
      "pricing": { "input": 1.00, "output": 3.00 },
      "contextWindow": 32000,
      "maxTokens": 8000,
      "supportsVision": false,
      "supportsFunction": true
    },
    "open-mixtral-8x22b": {
      "id": "open-mixtral-8x22b",
      "name": "Mixtral 8x22B",
      "provider": "mistral",
      "category": "mistral",
      "source": "core",
      "description": "Large mixture of experts model",
      "pricing": { "input": 1.2, "output": 1.2 },
      "contextWindow": 65536,
      "maxTokens": 8000,
      "supportsVision": false,
      "supportsFunction": true
    },
    "mistral-small-latest": {
      "id": "mistral-small-latest",
      "name": "Mistral Small",
      "provider": "mistral",
      "category": "mistral",
      "source": "core",
      "description": "Latest small model with vision support",
      "pricing": { "input": 0.2, "output": 0.6 },
      "contextWindow": 131072,
      "maxTokens": 8000,
      "supportsVision": true,
      "supportsFunction": true
    },
    "mistral-medium-latest": {
      "id": "mistral-medium-latest",
      "name": "Mistral Medium",
      "provider": "mistral",
      "category": "mistral",
      "source": "core",
      "description": "Latest medium model with vision support",
      "pricing": { "input": 1.0, "output": 3.0 },
      "contextWindow": 131072,
      "maxTokens": 8000,
      "supportsVision": true,
      "supportsFunction": true
    },
    "pixtral-large-latest": {
      "id": "pixtral-large-latest",
      "name": "Pixtral Large",
      "provider": "mistral",
      "category": "mistral",
      "source": "core",
      "description": "Large multimodal model with advanced vision",
      "pricing": { "input": 2.0, "output": 6.0 },
      "contextWindow": 131072,
      "maxTokens": 8000,
      "supportsVision": true,
      "supportsFunction": true
    },
    "pixtral-12b-latest": {
      "id": "pixtral-12b-latest",
      "name": "Pixtral 12B",
      "provider": "mistral",
      "category": "mistral",
      "source": "core",
      "description": "Compact multimodal model",
      "pricing": { "input": 0.15, "output": 0.15 },
      "contextWindow": 131072,
      "maxTokens": 8000,
      "supportsVision": true,
      "supportsFunction": true
    },
    "open-mistral-nemo": {
      "id": "open-mistral-nemo",
      "name": "Mistral Nemo",
      "provider": "mistral",
      "category": "mistral",
      "source": "core",
      "description": "Advanced open source model with large context",
      "pricing": { "input": 0.15, "output": 0.15 },
      "contextWindow": 131072,
      "maxTokens": 8000,
      "supportsVision": false,
      "supportsFunction": true
    },

    "llama-3.1-405b-reasoning": {
      "id": "llama-3.1-405b-reasoning",
      "name": "Llama 3.1 405B",
      "provider": "groq",
      "category": "llama",
      "source": "core",
      "description": "Largest open source model with strong reasoning",
      "pricing": { "input": 0, "output": 0 },
      "contextWindow": 131072,
      "maxTokens": 8000,
      "supportsVision": false,
      "supportsFunction": true
    },
    "llama-3.1-70b-versatile": {
      "id": "llama-3.1-70b-versatile",
      "name": "Llama 3.1 70B",
      "provider": "groq",
      "category": "llama",
      "source": "core",
      "description": "Versatile model for various tasks",
      "pricing": { "input": 0, "output": 0 },
      "contextWindow": 131072,
      "maxTokens": 8000,
      "supportsVision": false,
      "supportsFunction": true
    },
    "llama-3.1-8b-instant": {
      "id": "llama-3.1-8b-instant",
      "name": "Llama 3.1 8B",
      "provider": "groq",
      "category": "llama",
      "source": "core",
      "description": "Fast and efficient model",
      "pricing": { "input": 0, "output": 0 },
      "contextWindow": 131072,
      "maxTokens": 8000,
      "supportsVision": false,
      "supportsFunction": true
    },

    "gpt-4o-mini-tts": {
      "id": "gpt-4o-mini-tts",
      "name": "GPT-4o Mini TTS: Advanced",
      "provider": "openai",
      "category": "voice",
      "source": "core",
      "description": "Most reliable text-to-speech model with intelligent controls",
      "pricing": { "input": 0.15, "output": 0.60 },
      "contextWindow": 128000,
      "maxTokens": 16000,
      "supportsVision": false,
      "supportsFunction": false,
      "supportsTextToSpeech": true,
      "voiceOptions": ["alloy", "ash", "ballad", "coral", "echo", "fable", "nova", "onyx", "sage", "shimmer"],
      "audioFormats": ["mp3", "opus", "aac", "flac", "wav", "pcm"],
      "features": ["streaming", "instructions", "emotion_control", "speed_control", "accent_control"]
    },
    "tts-1-hd": {
      "id": "tts-1-hd",
      "name": "TTS-1 HD: High Quality",
      "provider": "openai",
      "category": "voice",
      "source": "core",
      "description": "High-definition text-to-speech model",
      "pricing": { "input": 0, "output": 0.015 },
      "contextWindow": 4000,
      "maxTokens": 1000,
      "supportsVision": false,
      "supportsFunction": false,
      "supportsTextToSpeech": true,
      "voiceOptions": ["alloy", "echo", "fable", "onyx", "nova", "shimmer"],
      "audioFormats": ["mp3", "opus", "aac", "flac"]
    },
    "tts-1": {
      "id": "tts-1",
      "name": "TTS-1: Standard",
      "provider": "openai",
      "category": "voice",
      "source": "core",
      "description": "Standard text-to-speech model with lower latency",
      "pricing": { "input": 0, "output": 0.015 },
      "contextWindow": 4000,
      "maxTokens": 1000,
      "supportsVision": false,
      "supportsFunction": false,
      "supportsTextToSpeech": true,
      "voiceOptions": ["alloy", "echo", "fable", "onyx", "nova", "shimmer"],
      "audioFormats": ["mp3", "opus", "aac", "flac"]
    },

    "gpt-4o-transcribe": {
      "id": "gpt-4o-transcribe",
      "name": "GPT-4o Transcribe: Best",
      "provider": "openai",
      "category": "voice",
      "source": "core",
      "description": "Highest quality speech-to-text model with intelligent prompting",
      "pricing": { "input": 2.50, "output": 10.00 },
      "contextWindow": 128000,
      "maxTokens": 16000,
      "supportsVision": false,
      "supportsFunction": false,
      "supportsSpeechToText": true,
      "audioFormats": ["mp3", "mp4", "mpeg", "mpga", "m4a", "wav", "webm"],
      "features": ["streaming", "prompting", "json_output", "text_output"],
      "maxFileSize": "25MB"
    },
    "gpt-4o-mini-transcribe": {
      "id": "gpt-4o-mini-transcribe",
      "name": "GPT-4o Mini Transcribe: Fast",
      "provider": "openai",
      "category": "voice",
      "source": "core",
      "description": "Fast and affordable speech-to-text model",
      "pricing": { "input": 0.15, "output": 0.60 },
      "contextWindow": 128000,
      "maxTokens": 16000,
      "supportsVision": false,
      "supportsFunction": false,
      "supportsSpeechToText": true,
      "audioFormats": ["mp3", "mp4", "mpeg", "mpga", "m4a", "wav", "webm"],
      "features": ["streaming", "prompting", "json_output", "text_output"],
      "maxFileSize": "25MB"
    },
    "whisper-1": {
      "id": "whisper-1",
      "name": "Whisper-1: Legacy",
      "provider": "openai",
      "category": "voice",
      "source": "core",
      "description": "Original Whisper speech-to-text model",
      "pricing": { "input": 0, "output": 0.006 },
      "contextWindow": 25000,
      "maxTokens": 1000,
      "supportsVision": false,
      "supportsFunction": false,
      "supportsSpeechToText": true,
      "audioFormats": ["mp3", "mp4", "mpeg", "mpga", "m4a", "wav", "webm"],
      "features": ["timestamps", "translations", "verbose_json", "srt", "vtt"],
      "maxFileSize": "25MB"
    },

    "gpt-image-1": {
      "id": "gpt-image-1",
      "name": "GPT Image 1: Advanced",
      "provider": "openai",
      "category": "image",
      "source": "core",
      "description": "Advanced multimodal image generation model",
      "pricing": { "input": 2.50, "output": 10.00 },
      "contextWindow": 128000,
      "maxTokens": 16000,
      "supportsVision": true,
      "supportsFunction": true,
      "supportsImageGeneration": true,
      "imageTokens": {
        "low": { "1024x1024": 272, "1024x1536": 408, "1536x1024": 400 },
        "medium": { "1024x1024": 1056, "1024x1536": 1584, "1536x1024": 1568 },
        "high": { "1024x1024": 4160, "1024x1536": 6240, "1536x1024": 6208 }
      }
    },
    "dall-e-3": {
      "id": "dall-e-3",
      "name": "DALL-E 3: Specialized",
      "provider": "openai",
      "category": "image",
      "source": "core",
      "description": "Specialized image generation model",
      "pricing": { "input": 0, "output": 0.04 },
      "contextWindow": 4000,
      "maxTokens": 1000,
      "supportsVision": false,
      "supportsFunction": false,
      "supportsImageGeneration": true,
      "imageConfig": {
        "quality": ["standard", "hd"],
        "size": ["1024x1024", "1024x1792", "1792x1024"],
        "style": ["vivid", "natural"]
      }
    },
    "dall-e-2": {
      "id": "dall-e-2",
      "name": "DALL-E 2: Fast",
      "provider": "openai",
      "category": "image",
      "source": "core",
      "description": "Fast image generation model",
      "pricing": { "input": 0, "output": 0.02 },
      "contextWindow": 1000,
      "maxTokens": 1000,
      "supportsVision": false,
      "supportsFunction": false,
      "supportsImageGeneration": true,
      "imageConfig": {
        "quality": ["standard"],
        "size": ["256x256", "512x512", "1024x1024"],
        "style": ["vivid", "natural"]
      }
    },

    "gemini-2.0-flash-preview-image-generation": {
      "id": "gemini-2.0-flash-preview-image-generation",
      "name": "Gemini 2.0 Flash: Image Generation",
      "provider": "google",
      "category": "image",
      "source": "core",
      "description": "Native Gemini conversational image generation with text and image outputs",
      "pricing": { "input": 0, "output": 0 },
      "contextWindow": 1000000,
      "maxTokens": 8000,
      "supportsVision": true,
      "supportsFunction": true,
      "supportsImageGeneration": true,
      "imageConfig": {
        "quality": ["standard"],
        "size": ["1:1"],
        "maxImages": 1,
        "supportsConversational": true,
        "supportsPromptEnhancement": true
      }
    },
    "imagen-4.0-generate-preview": {
      "id": "imagen-4.0-generate-preview",
      "name": "Imagen 4.0: Specialized Art",
      "provider": "google",
      "category": "image",
      "source": "core",
      "description": "Google's specialized image generation model optimized for photorealism and artistic detail",
      "pricing": { "input": 0, "output": 0 },
      "contextWindow": 1000,
      "maxTokens": 1000,
      "supportsVision": false,
      "supportsFunction": false,
      "supportsImageGeneration": true,
      "imageConfig": {
        "quality": ["standard"],
        "size": ["1:1", "3:4", "4:3", "9:16", "16:9"],
        "maxImages": 4,
        "supportsConversational": false,
        "supportsPromptEnhancement": true,
        "personGeneration": ["dont_allow", "allow_adult", "allow_all"]
      }
    },

    "gpt-4o-search-preview": {
      "id": "gpt-4o-search-preview",
      "name": "GPT-4o Search: Web-Enabled",
      "provider": "openai",
      "category": "search",
      "source": "core",
      "description": "GPT-4o with integrated web search capabilities",
      "pricing": { "input": 5.00, "output": 15.00, "search": 10.00 },
      "contextWindow": 128000,
      "maxTokens": 16000,
      "supportsVision": true,
      "supportsFunction": true,
      "supportsWebSearch": true,
      "webSearchType": "chat_completions"
    },
    "gpt-4o-mini-search-preview": {
      "id": "gpt-4o-mini-search-preview",
      "name": "GPT-4o Mini Search: Fast Web",
      "provider": "openai",
      "category": "search",
      "source": "core",
      "description": "GPT-4o Mini with integrated web search capabilities",
      "pricing": { "input": 0.15, "output": 0.60, "search": 10.00 },
      "contextWindow": 128000,
      "maxTokens": 16000,
      "supportsVision": true,
      "supportsFunction": true,
      "supportsWebSearch": true,
      "webSearchType": "chat_completions"
    },

    "o3-deep-research": {
      "id": "o3-deep-research",
      "name": "o3 Deep Research: Advanced Research",
      "provider": "openai",
      "category": "search",
      "source": "core",
      "description": "Our most powerful deep research model for complex, multi-step research tasks with web search and data synthesis",
      "pricing": { "input": 10.00, "output": 40.00, "cached": 2.50 },
      "contextWindow": 200000,
      "maxTokens": 100000,
      "supportsVision": true,
      "supportsFunction": true,
      "supportsWebSearch": true,
      "supportsDeepResearch": true,
      "supportsReasoningTokens": true,
      "webSearchType": "responses",
      "knowledgeCutoff": "2024-05-31"
    },

    "o4-mini-deep-research": {
      "id": "o4-mini-deep-research",
      "name": "o4 Mini Deep Research: Fast Research",
      "provider": "openai",
      "category": "search",
      "source": "core",
      "description": "Faster, more affordable deep research model for complex, multi-step research tasks with web search",
      "pricing": { "input": 2.00, "output": 8.00, "cached": 0.50 },
      "contextWindow": 200000,
      "maxTokens": 100000,
      "supportsVision": true,
      "supportsFunction": true,
      "supportsWebSearch": true,
      "supportsDeepResearch": true,
      "supportsReasoningTokens": true,
      "webSearchType": "responses",
      "knowledgeCutoff": "2024-05-31"
    },

    "grok-4": {
      "id": "grok-4",
      "name": "Grok 4: Advanced Reasoning",
      "provider": "grok",
      "category": "grok",
      "source": "core",
      "description": "Most advanced Grok model with built-in reasoning, vision, and function calling",
      "pricing": { "input": 3.00, "output": 15.00 },
      "contextWindow": 256000,
      "maxTokens": 16000,
      "supportsVision": true,
      "supportsFunction": true,
      "supportsReasoning": true,
      "supportsStructuredOutputs": true
    },
    "grok-4-0709": {
      "id": "grok-4-0709",
      "name": "Grok 4 (0709): Reasoning Model",
      "provider": "grok",
      "category": "grok",
      "source": "core",
      "description": "Specific version of Grok 4 with enhanced reasoning capabilities",
      "pricing": { "input": 3.00, "output": 15.00 },
      "contextWindow": 256000,
      "maxTokens": 16000,
      "supportsVision": true,
      "supportsFunction": true,
      "supportsReasoning": true,
      "supportsStructuredOutputs": true
    },
    "grok-3": {
      "id": "grok-3",
      "name": "Grok 3: Flagship Model",
      "provider": "grok",
      "category": "grok",
      "source": "core",
      "description": "High-performance Grok model for general-purpose tasks",
      "pricing": { "input": 3.00, "output": 15.00 },
      "contextWindow": 131072,
      "maxTokens": 8000,
      "supportsVision": false,
      "supportsFunction": true,
      "supportsReasoning": false,
      "supportsStructuredOutputs": true
    },
    "grok-3-mini": {
      "id": "grok-3-mini",
      "name": "Grok 3 Mini: Affordable",
      "provider": "grok",
      "category": "grok",
      "source": "core",
      "description": "Most affordable Grok model for cost-effective AI applications",
      "pricing": { "input": 0.30, "output": 0.50 },
      "contextWindow": 131072,
      "maxTokens": 8000,
      "supportsVision": false,
      "supportsFunction": true,
      "supportsReasoning": false,
      "supportsStructuredOutputs": true
    },
    "grok-3-fast": {
      "id": "grok-3-fast",
      "name": "Grok 3 Fast: High Speed",
      "provider": "grok",
      "category": "grok",
      "source": "core",
      "description": "Fast Grok model optimized for low latency applications",
      "pricing": { "input": 5.00, "output": 25.00 },
      "contextWindow": 131072,
      "maxTokens": 8000,
      "supportsVision": false,
      "supportsFunction": true,
      "supportsReasoning": false,
      "supportsStructuredOutputs": true
    },
    "grok-3-mini-fast": {
      "id": "grok-3-mini-fast",
      "name": "Grok 3 Mini Fast: Budget Speed",
      "provider": "grok",
      "category": "grok",
      "source": "core",
      "description": "Affordable fast Grok model balancing cost and speed",
      "pricing": { "input": 0.60, "output": 4.00 },
      "contextWindow": 131072,
      "maxTokens": 8000,
      "supportsVision": false,
      "supportsFunction": true,
      "supportsReasoning": false,
      "supportsStructuredOutputs": true
    },
    "grok-2-vision-1212": {
      "id": "grok-2-vision-1212",
      "name": "Grok 2 Vision: Multimodal",
      "provider": "grok",
      "category": "grok",
      "source": "core",
      "description": "Grok model with vision capabilities for image understanding",
      "pricing": { "input": 2.00, "output": 10.00 },
      "contextWindow": 32768,
      "maxTokens": 4000,
      "supportsVision": true,
      "supportsFunction": false,
      "supportsReasoning": false,
      "supportsStructuredOutputs": false
    },
    "grok-2-image-1212": {
      "id": "grok-2-image-1212",
      "name": "Grok 2 Image: Generation",
      "provider": "grok",
      "category": "image",
      "source": "core",
      "description": "Grok model specialized for image generation tasks",
      "pricing": { "input": 0, "output": 0.07 },
      "contextWindow": 1000,
      "maxTokens": 1000,
      "supportsVision": false,
      "supportsFunction": false,
      "supportsImageGeneration": true,
      "imageConfig": {
        "response_format": ["url", "b64_json"],
        "n": { "min": 1, "max": 10 }
      }
    },

    "kimi-k2-0711-preview": {
      "id": "kimi-k2-0711-preview",
      "name": "Kimi K2: Advanced Reasoning",
      "provider": "kimi",
      "category": "deepseek",
      "source": "core",
      "description": "Moonshot AI's flagship model with 1T parameters, optimized for long context, reasoning, and agentic behavior",
      "pricing": { "input": 0.15, "output": 2.50 },
      "contextWindow": 200000,
      "maxTokens": 8000,
      "supportsVision": false,
      "supportsFunction": true,
      "supportsReasoning": true,
      "supportsLongContext": true
    }
  },
  
  "categories": {
    "gpt": {
      "name": "GPT Models",
      "models": ["gpt-5", "gpt-5-mini", "gpt-5-nano", "gpt-5-chat-latest", "gpt-4", "gpt-4-turbo", "gpt-4o", "gpt-4.1", "gpt-4o-mini", "gpt-4.1-mini", "gpt-4.1-nano", "gpt-3.5-turbo-0125"]
    },
    "claude": {
      "name": "Claude Models",
      "models": ["claude-opus-4-20250514", "claude-sonnet-4-20250514", "claude-3-7-sonnet-latest", "claude-3-5-sonnet-latest", "claude-3-5-haiku-latest", "claude-3-haiku-20240307"]
    },
    "gemini": {
      "name": "Gemini Models",
      "models": ["gemini-2.5-pro-preview-05-06", "gemini-2.5-flash-preview-05-20", "gemini-2.0-flash-exp", "gemini-2.0-flash-lite", "gemini-1.5-pro", "gemini-1.5-flash", "gemini-1.5-flash-8b", "gemini-pro"]
    },
    "deepseek": {
      "name": "Chinese AI Models",
      "models": ["deepseek-reasoner", "deepseek-chat", "kimi-k2-0711-preview"]
    },
    "reasoning": {
      "name": "Reasoning Models",
      "models": ["o4-mini", "o3-pro", "o3", "o3-mini", "o1-pro", "o1-preview", "o1-mini"]
    },
    "mistral": {
      "name": "Mistral Models",
      "models": ["mistral-large-latest", "mistral-medium-latest", "mistral-small-latest", "pixtral-large-latest", "pixtral-12b-latest", "open-mixtral-8x22b", "open-mistral-nemo", "codestral-latest"]
    },
    "llama": {
      "name": "LLaMA Models",
      "models": ["llama-3.1-405b-reasoning", "llama-3.1-70b-versatile", "llama-3.1-8b-instant"]
    },
    "voice": {
      "name": "Voice Models",
      "models": ["gpt-4o-mini-tts", "tts-1-hd", "tts-1", "gpt-4o-transcribe", "gpt-4o-mini-transcribe", "whisper-1"]
    },
    "image": {
      "name": "Image Models",
      "models": ["gpt-image-1", "dall-e-3", "dall-e-2", "gemini-2.0-flash-preview-image-generation", "imagen-4.0-generate-preview", "grok-2-image-1212"]
    },
    "search": {
      "name": "Web Search Models",
      "models": ["o3-deep-research", "o4-mini-deep-research", "gpt-4o-search-preview", "gpt-4o-mini-search-preview"]
    },
    "grok": {
      "name": "Grok Models",
      "models": ["grok-4", "grok-4-0709", "grok-3", "grok-3-mini", "grok-3-fast", "grok-3-mini-fast", "grok-2-vision-1212"]
    }
  }
}